{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spaCy-training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTQ-BoJHkxgi",
        "colab_type": "text"
      },
      "source": [
        "# Command line spaCy training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBq8uwVWk13I",
        "colab_type": "text"
      },
      "source": [
        "## Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXZPcarXkp3W",
        "colab_type": "code",
        "outputId": "e4110704-33e4-4ac7-9bd2-cbb35300f36f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "train_url = 'https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/train.txt'\n",
        "valid_url = 'https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/valid.txt'\n",
        "test_url = 'https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/test.txt'\n",
        "\n",
        "train_file = 'train.txt'\n",
        "valid_file = 'valid.txt'\n",
        "test_file = 'test.txt'\n",
        "\n",
        "!wget $train_url -O $train_file\n",
        "!wget $valid_url -O $valid_file\n",
        "!wget $test_url -O $test_file"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-30 14:59:08--  https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3283418 (3.1M) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "\rtrain.txt             0%[                    ]       0  --.-KB/s               \rtrain.txt           100%[===================>]   3.13M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-04-30 14:59:08 (58.2 MB/s) - ‘train.txt’ saved [3283418/3283418]\n",
            "\n",
            "--2020-04-30 14:59:09--  https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 827441 (808K) [text/plain]\n",
            "Saving to: ‘valid.txt’\n",
            "\n",
            "valid.txt           100%[===================>] 808.05K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-04-30 14:59:09 (21.8 MB/s) - ‘valid.txt’ saved [827441/827441]\n",
            "\n",
            "--2020-04-30 14:59:10--  https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 748093 (731K) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "test.txt            100%[===================>] 730.56K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-04-30 14:59:10 (11.0 MB/s) - ‘test.txt’ saved [748093/748093]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bfV_DK2lH-t",
        "colab_type": "text"
      },
      "source": [
        "## Convert datasets to spaCy json format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqjauCVulG_w",
        "colab_type": "code",
        "outputId": "82aa18ae-b05d-46c2-b138-1adafec8fb04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!python -m spacy convert -c iob $train_file . -n 10\n",
        "!python -m spacy convert -c ner $valid_file . -n 10\n",
        "!python -m spacy convert -c ner $test_file . -n 10"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (1499 documents): train.json\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (347 documents): valid.json\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (369 documents): test.json\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9DI7Vj9lSZD",
        "colab_type": "text"
      },
      "source": [
        "## Check json files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foCUaFjnlRpy",
        "colab_type": "code",
        "outputId": "c30b2b41-53b3-453f-e8c0-ceb9c240d522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import json\n",
        "\n",
        "train_json = train_file[:-4] + '.json'\n",
        "valid_json = valid_file[:-4] + '.json'\n",
        "test_json = test_file[:-4] + '.json'\n",
        "\n",
        "with open(train_json, 'r') as f:\n",
        "  train_data = json.load(f)\n",
        "\n",
        "train_data[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 0,\n",
              " 'paragraphs': [{'sentences': [{'tokens': [{'ner': 'O',\n",
              "       'orth': '-DOCSTART-',\n",
              "       'tag': '-X-'}]},\n",
              "    {'tokens': [{'ner': 'U-ORG', 'orth': 'EU', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'rejects', 'tag': 'VBZ'},\n",
              "      {'ner': 'U-MISC', 'orth': 'German', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'call', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'boycott', 'tag': 'VB'},\n",
              "      {'ner': 'U-MISC', 'orth': 'British', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'lamb', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'B-PER', 'orth': 'Peter', 'tag': 'NNP'},\n",
              "      {'ner': 'L-PER', 'orth': 'Blackburn', 'tag': 'NNP'}]},\n",
              "    {'tokens': [{'ner': 'U-LOC', 'orth': 'BRUSSELS', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': '1996-08-22', 'tag': 'CD'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'The', 'tag': 'DT'},\n",
              "      {'ner': 'B-ORG', 'orth': 'European', 'tag': 'NNP'},\n",
              "      {'ner': 'L-ORG', 'orth': 'Commission', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'said', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'on', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'Thursday', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'it', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': 'disagreed', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'with', 'tag': 'IN'},\n",
              "      {'ner': 'U-MISC', 'orth': 'German', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'advice', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'consumers', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'shun', 'tag': 'VB'},\n",
              "      {'ner': 'U-MISC', 'orth': 'British', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'lamb', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'until', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'scientists', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'determine', 'tag': 'VBP'},\n",
              "      {'ner': 'O', 'orth': 'whether', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'mad', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'cow', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'disease', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'can', 'tag': 'MD'},\n",
              "      {'ner': 'O', 'orth': 'be', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'transmitted', 'tag': 'VBN'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'sheep', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'U-LOC', 'orth': 'Germany', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': \"'s\", 'tag': 'POS'},\n",
              "      {'ner': 'O', 'orth': 'representative', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'B-ORG', 'orth': 'European', 'tag': 'NNP'},\n",
              "      {'ner': 'L-ORG', 'orth': 'Union', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': \"'s\", 'tag': 'POS'},\n",
              "      {'ner': 'O', 'orth': 'veterinary', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'committee', 'tag': 'NN'},\n",
              "      {'ner': 'B-PER', 'orth': 'Werner', 'tag': 'NNP'},\n",
              "      {'ner': 'L-PER', 'orth': 'Zwingmann', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'said', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'on', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'Wednesday', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'consumers', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'should', 'tag': 'MD'},\n",
              "      {'ner': 'O', 'orth': 'buy', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'sheepmeat', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'from', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'countries', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'other', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'than', 'tag': 'IN'},\n",
              "      {'ner': 'U-LOC', 'orth': 'Britain', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'until', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'scientific', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'advice', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'was', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'clearer', 'tag': 'JJR'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': '\"', 'tag': '\"'},\n",
              "      {'ner': 'O', 'orth': 'We', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': 'do', 'tag': 'VBP'},\n",
              "      {'ner': 'O', 'orth': \"n't\", 'tag': 'RB'},\n",
              "      {'ner': 'O', 'orth': 'support', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'any', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'such', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'recommendation', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'because', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'we', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': 'do', 'tag': 'VBP'},\n",
              "      {'ner': 'O', 'orth': \"n't\", 'tag': 'RB'},\n",
              "      {'ner': 'O', 'orth': 'see', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'any', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'grounds', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'for', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'it', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': '\"', 'tag': '\"'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'U-ORG', 'orth': 'Commission', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': \"'s\", 'tag': 'POS'},\n",
              "      {'ner': 'O', 'orth': 'chief', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'spokesman', 'tag': 'NN'},\n",
              "      {'ner': 'B-PER', 'orth': 'Nikolaus', 'tag': 'NNP'},\n",
              "      {'ner': 'I-PER', 'orth': 'van', 'tag': 'NNP'},\n",
              "      {'ner': 'I-PER', 'orth': 'der', 'tag': 'FW'},\n",
              "      {'ner': 'L-PER', 'orth': 'Pas', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'told', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'news', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'briefing', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'He', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': 'said', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'further', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'scientific', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'study', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'was', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'required', 'tag': 'VBN'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'O', 'orth': 'if', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'it', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': 'was', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'found', 'tag': 'VBN'},\n",
              "      {'ner': 'O', 'orth': 'that', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'action', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'was', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'needed', 'tag': 'VBN'},\n",
              "      {'ner': 'O', 'orth': 'it', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': 'should', 'tag': 'MD'},\n",
              "      {'ner': 'O', 'orth': 'be', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'taken', 'tag': 'VBN'},\n",
              "      {'ner': 'O', 'orth': 'by', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'B-ORG', 'orth': 'European', 'tag': 'NNP'},\n",
              "      {'ner': 'L-ORG', 'orth': 'Union', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'He', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': 'said', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'proposal', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'last', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'month', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'by', 'tag': 'IN'},\n",
              "      {'ner': 'U-ORG', 'orth': 'EU', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'Farm', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'Commissioner', 'tag': 'NNP'},\n",
              "      {'ner': 'B-PER', 'orth': 'Franz', 'tag': 'NNP'},\n",
              "      {'ner': 'L-PER', 'orth': 'Fischler', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'ban', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'sheep', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'brains', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'spleens', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'O', 'orth': 'spinal', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'cords', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'from', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'human', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'O', 'orth': 'animal', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'food', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'chains', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'was', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'highly', 'tag': 'RB'},\n",
              "      {'ner': 'O', 'orth': 'specific', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'O', 'orth': 'precautionary', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'move', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'protect', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'human', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'health', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'U-PER', 'orth': 'Fischler', 'tag': 'JJR'},\n",
              "      {'ner': 'O', 'orth': 'proposed', 'tag': 'VBN'},\n",
              "      {'ner': 'U-MISC', 'orth': 'EU-wide', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'measures', 'tag': 'VBZ'},\n",
              "      {'ner': 'O', 'orth': 'after', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'reports', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'from', 'tag': 'IN'},\n",
              "      {'ner': 'U-LOC', 'orth': 'Britain', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'U-LOC', 'orth': 'France', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'that', 'tag': 'WDT'},\n",
              "      {'ner': 'O', 'orth': 'under', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'laboratory', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'conditions', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'sheep', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'could', 'tag': 'MD'},\n",
              "      {'ner': 'O', 'orth': 'contract', 'tag': 'VB'},\n",
              "      {'ner': 'B-MISC', 'orth': 'Bovine', 'tag': 'NNP'},\n",
              "      {'ner': 'I-MISC', 'orth': 'Spongiform', 'tag': 'NNP'},\n",
              "      {'ner': 'L-MISC', 'orth': 'Encephalopathy', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': '(', 'tag': '('},\n",
              "      {'ner': 'U-MISC', 'orth': 'BSE', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': ')', 'tag': ')'},\n",
              "      {'ner': 'O', 'orth': '--', 'tag': ':'},\n",
              "      {'ner': 'O', 'orth': 'mad', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'cow', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'disease', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]}]}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND2g8koil4Vi",
        "colab_type": "code",
        "outputId": "d4e0c347-9f6a-409c-c9eb-ce486d2814aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with open(valid_json, 'r') as f:\n",
        "  valid_data = json.load(f)\n",
        "\n",
        "valid_data[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 0,\n",
              " 'paragraphs': [{'sentences': [{'tokens': [{'ner': 'O',\n",
              "       'orth': '-DOCSTART-',\n",
              "       'tag': '-X-'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'CRICKET', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': '-', 'tag': ':'},\n",
              "      {'ner': 'U-ORG', 'orth': 'LEICESTERSHIRE', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'TAKE', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'OVER', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'AT', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'TOP', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'AFTER', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'INNINGS', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'VICTORY', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'U-LOC', 'orth': 'LONDON', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': '1996-08-30', 'tag': 'CD'}]},\n",
              "    {'tokens': [{'ner': 'B-MISC', 'orth': 'West', 'tag': 'NNP'},\n",
              "      {'ner': 'L-MISC', 'orth': 'Indian', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'all-rounder', 'tag': 'NN'},\n",
              "      {'ner': 'B-PER', 'orth': 'Phil', 'tag': 'NNP'},\n",
              "      {'ner': 'L-PER', 'orth': 'Simmons', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'took', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'four', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'for', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': '38', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'on', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'Friday', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'as', 'tag': 'IN'},\n",
              "      {'ner': 'U-ORG', 'orth': 'Leicestershire', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'beat', 'tag': 'VBD'},\n",
              "      {'ner': 'U-ORG', 'orth': 'Somerset', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'by', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'an', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'innings', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'O', 'orth': '39', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'runs', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'in', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'two', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'days', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'take', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'over', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'at', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'head', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'of', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'county', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'championship', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'Their', 'tag': 'PRP$'},\n",
              "      {'ner': 'O', 'orth': 'stay', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'on', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'top', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'though', 'tag': 'RB'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'may', 'tag': 'MD'},\n",
              "      {'ner': 'O', 'orth': 'be', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'short-lived', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'as', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'title', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'rivals', 'tag': 'NNS'},\n",
              "      {'ner': 'U-ORG', 'orth': 'Essex', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'U-ORG', 'orth': 'Derbyshire', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'U-ORG', 'orth': 'Surrey', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'all', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'closed', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'in', 'tag': 'RP'},\n",
              "      {'ner': 'O', 'orth': 'on', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'victory', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'while', 'tag': 'IN'},\n",
              "      {'ner': 'U-ORG', 'orth': 'Kent', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'made', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'up', 'tag': 'RP'},\n",
              "      {'ner': 'O', 'orth': 'for', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'lost', 'tag': 'VBN'},\n",
              "      {'ner': 'O', 'orth': 'time', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'in', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'their', 'tag': 'PRP$'},\n",
              "      {'ner': 'O', 'orth': 'rain-affected', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'match', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'against', 'tag': 'IN'},\n",
              "      {'ner': 'U-ORG', 'orth': 'Nottinghamshire', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'After', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'bowling', 'tag': 'VBG'},\n",
              "      {'ner': 'U-ORG', 'orth': 'Somerset', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'out', 'tag': 'RP'},\n",
              "      {'ner': 'O', 'orth': 'for', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': '83', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'on', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'opening', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'morning', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'at', 'tag': 'IN'},\n",
              "      {'ner': 'B-LOC', 'orth': 'Grace', 'tag': 'NNP'},\n",
              "      {'ner': 'L-LOC', 'orth': 'Road', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'U-ORG', 'orth': 'Leicestershire', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'extended', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'their', 'tag': 'PRP$'},\n",
              "      {'ner': 'O', 'orth': 'first', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'innings', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'by', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': '94', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'runs', 'tag': 'VBZ'},\n",
              "      {'ner': 'O', 'orth': 'before', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'being', 'tag': 'VBG'},\n",
              "      {'ner': 'O', 'orth': 'bowled', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'out', 'tag': 'RP'},\n",
              "      {'ner': 'O', 'orth': 'for', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': '296', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'with', 'tag': 'IN'},\n",
              "      {'ner': 'U-LOC', 'orth': 'England', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'discard', 'tag': 'VBP'},\n",
              "      {'ner': 'B-PER', 'orth': 'Andy', 'tag': 'NNP'},\n",
              "      {'ner': 'L-PER', 'orth': 'Caddick', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'taking', 'tag': 'VBG'},\n",
              "      {'ner': 'O', 'orth': 'three', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'for', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': '83', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'Trailing', 'tag': 'VBG'},\n",
              "      {'ner': 'O', 'orth': 'by', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': '213', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'U-ORG', 'orth': 'Somerset', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'got', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'solid', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'start', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'their', 'tag': 'PRP$'},\n",
              "      {'ner': 'O', 'orth': 'second', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'innings', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'before', 'tag': 'IN'},\n",
              "      {'ner': 'U-PER', 'orth': 'Simmons', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'stepped', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'in', 'tag': 'RP'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'bundle', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'them', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': 'out', 'tag': 'RB'},\n",
              "      {'ner': 'O', 'orth': 'for', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': '174', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'U-ORG', 'orth': 'Essex', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'however', 'tag': 'RB'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'look', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'certain', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'regain', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'their', 'tag': 'PRP$'},\n",
              "      {'ner': 'O', 'orth': 'top', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'spot', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'after', 'tag': 'IN'},\n",
              "      {'ner': 'B-PER', 'orth': 'Nasser', 'tag': 'NNP'},\n",
              "      {'ner': 'L-PER', 'orth': 'Hussain', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'B-PER', 'orth': 'Peter', 'tag': 'NNP'},\n",
              "      {'ner': 'L-PER', 'orth': 'Such', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'gave', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'them', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'firm', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'grip', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'on', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'their', 'tag': 'PRP$'},\n",
              "      {'ner': 'O', 'orth': 'match', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'against', 'tag': 'IN'},\n",
              "      {'ner': 'U-ORG', 'orth': 'Yorkshire', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'at', 'tag': 'IN'},\n",
              "      {'ner': 'U-LOC', 'orth': 'Headingley', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'U-PER', 'orth': 'Hussain', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'considered', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'surplus', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'U-LOC', 'orth': 'England', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': \"'s\", 'tag': 'POS'},\n",
              "      {'ner': 'O', 'orth': 'one-day', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'requirements', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'struck', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': '158', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'his', 'tag': 'PRP$'},\n",
              "      {'ner': 'O', 'orth': 'first', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'championship', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'century', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'of', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'season', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'as', 'tag': 'IN'},\n",
              "      {'ner': 'U-ORG', 'orth': 'Essex', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'reached', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': '372', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'O', 'orth': 'took', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'first', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'innings', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'lead', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'of', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': '82', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'By', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'close', 'tag': 'NN'},\n",
              "      {'ner': 'U-ORG', 'orth': 'Yorkshire', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'had', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'turned', 'tag': 'VBN'},\n",
              "      {'ner': 'O', 'orth': 'that', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'into', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': '37-run', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'advantage', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'but', 'tag': 'CC'},\n",
              "      {'ner': 'O', 'orth': 'off-spinner', 'tag': 'JJ'},\n",
              "      {'ner': 'U-PER', 'orth': 'Such', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'had', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'scuttled', 'tag': 'VBN'},\n",
              "      {'ner': 'O', 'orth': 'their', 'tag': 'PRP$'},\n",
              "      {'ner': 'O', 'orth': 'hopes', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'taking', 'tag': 'VBG'},\n",
              "      {'ner': 'O', 'orth': 'four', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'for', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': '24', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'in', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': '48', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'balls', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'O', 'orth': 'leaving', 'tag': 'VBG'},\n",
              "      {'ner': 'O', 'orth': 'them', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': 'hanging', 'tag': 'VBG'},\n",
              "      {'ner': 'O', 'orth': 'on', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': '119', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'for', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'five', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'O', 'orth': 'praying', 'tag': 'VBG'},\n",
              "      {'ner': 'O', 'orth': 'for', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'rain', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]}]}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP3SgEKTnJ5M",
        "colab_type": "code",
        "outputId": "dbdb60bd-dddb-473f-a5dd-49b84aeb5b03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with open(test_json, 'r') as f:\n",
        "  test_data = json.load(f)\n",
        "\n",
        "test_data[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 0,\n",
              " 'paragraphs': [{'sentences': [{'tokens': [{'ner': 'O',\n",
              "       'orth': '-DOCSTART-',\n",
              "       'tag': '-X-'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'SOCCER', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '-', 'tag': ':'},\n",
              "      {'ner': 'U-LOC', 'orth': 'JAPAN', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'GET', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'LUCKY', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'WIN', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'U-PER', 'orth': 'CHINA', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'IN', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'SURPRISE', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'DEFEAT', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'B-PER', 'orth': 'Nadim', 'tag': 'NNP'},\n",
              "      {'ner': 'L-PER', 'orth': 'Ladki', 'tag': 'NNP'}]},\n",
              "    {'tokens': [{'ner': 'U-LOC', 'orth': 'AL-AIN', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'B-LOC', 'orth': 'United', 'tag': 'NNP'},\n",
              "      {'ner': 'I-LOC', 'orth': 'Arab', 'tag': 'NNP'},\n",
              "      {'ner': 'L-LOC', 'orth': 'Emirates', 'tag': 'NNPS'},\n",
              "      {'ner': 'O', 'orth': '1996-12-06', 'tag': 'CD'}]},\n",
              "    {'tokens': [{'ner': 'U-LOC', 'orth': 'Japan', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'began', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'defence', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'of', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'their', 'tag': 'PRP$'},\n",
              "      {'ner': 'B-MISC', 'orth': 'Asian', 'tag': 'JJ'},\n",
              "      {'ner': 'L-MISC', 'orth': 'Cup', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'title', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'with', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'lucky', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': '2-1', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'win', 'tag': 'VBP'},\n",
              "      {'ner': 'O', 'orth': 'against', 'tag': 'IN'},\n",
              "      {'ner': 'U-LOC', 'orth': 'Syria', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'in', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'Group', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'C', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'championship', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'match', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'on', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'Friday', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'But', 'tag': 'CC'},\n",
              "      {'ner': 'U-LOC', 'orth': 'China', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'saw', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'their', 'tag': 'PRP$'},\n",
              "      {'ner': 'O', 'orth': 'luck', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'desert', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'them', 'tag': 'PRP'},\n",
              "      {'ner': 'O', 'orth': 'in', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'second', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'match', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'of', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'group', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'crashing', 'tag': 'VBG'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'surprise', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '2-0', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'defeat', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'newcomers', 'tag': 'NNS'},\n",
              "      {'ner': 'U-LOC', 'orth': 'Uzbekistan', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'U-LOC', 'orth': 'China', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'controlled', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'most', 'tag': 'JJS'},\n",
              "      {'ner': 'O', 'orth': 'of', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'match', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'O', 'orth': 'saw', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'several', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'chances', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'missed', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'until', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': '78th', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'minute', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'when', 'tag': 'WRB'},\n",
              "      {'ner': 'U-MISC', 'orth': 'Uzbek', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'striker', 'tag': 'NN'},\n",
              "      {'ner': 'B-PER', 'orth': 'Igor', 'tag': 'JJ'},\n",
              "      {'ner': 'L-PER', 'orth': 'Shkvyrin', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'took', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'advantage', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'of', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'misdirected', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'defensive', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'header', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'to', 'tag': 'TO'},\n",
              "      {'ner': 'O', 'orth': 'lob', 'tag': 'VB'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'ball', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'over', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'advancing', 'tag': 'VBG'},\n",
              "      {'ner': 'U-MISC', 'orth': 'Chinese', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'keeper', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'and', 'tag': 'CC'},\n",
              "      {'ner': 'O', 'orth': 'into', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'an', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'empty', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'net', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'B-PER', 'orth': 'Oleg', 'tag': 'NNP'},\n",
              "      {'ner': 'L-PER', 'orth': 'Shatskiku', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'made', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'sure', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'of', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'win', 'tag': 'VBP'},\n",
              "      {'ner': 'O', 'orth': 'in', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'injury', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'time', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'O', 'orth': 'hitting', 'tag': 'VBG'},\n",
              "      {'ner': 'O', 'orth': 'an', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'unstoppable', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'left', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'foot', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'shot', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'from', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'just', 'tag': 'RB'},\n",
              "      {'ner': 'O', 'orth': 'outside', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'area', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'The', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'former', 'tag': 'JJ'},\n",
              "      {'ner': 'U-MISC', 'orth': 'Soviet', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'republic', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'was', 'tag': 'VBD'},\n",
              "      {'ner': 'O', 'orth': 'playing', 'tag': 'VBG'},\n",
              "      {'ner': 'O', 'orth': 'in', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'an', 'tag': 'DT'},\n",
              "      {'ner': 'B-MISC', 'orth': 'Asian', 'tag': 'NNP'},\n",
              "      {'ner': 'L-MISC', 'orth': 'Cup', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'finals', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'tie', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'for', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'first', 'tag': 'JJ'},\n",
              "      {'ner': 'O', 'orth': 'time', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]},\n",
              "    {'tokens': [{'ner': 'O', 'orth': 'Despite', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'winning', 'tag': 'VBG'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'B-MISC', 'orth': 'Asian', 'tag': 'JJ'},\n",
              "      {'ner': 'L-MISC', 'orth': 'Games', 'tag': 'NNPS'},\n",
              "      {'ner': 'O', 'orth': 'title', 'tag': 'NN'},\n",
              "      {'ner': 'O', 'orth': 'two', 'tag': 'CD'},\n",
              "      {'ner': 'O', 'orth': 'years', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'ago', 'tag': 'RB'},\n",
              "      {'ner': 'O', 'orth': ',', 'tag': ','},\n",
              "      {'ner': 'U-LOC', 'orth': 'Uzbekistan', 'tag': 'NNP'},\n",
              "      {'ner': 'O', 'orth': 'are', 'tag': 'VBP'},\n",
              "      {'ner': 'O', 'orth': 'in', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'the', 'tag': 'DT'},\n",
              "      {'ner': 'O', 'orth': 'finals', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': 'as', 'tag': 'IN'},\n",
              "      {'ner': 'O', 'orth': 'outsiders', 'tag': 'NNS'},\n",
              "      {'ner': 'O', 'orth': '.', 'tag': '.'}]}]}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK5nmmQxr9Up",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUjVf67uoHMV",
        "colab_type": "code",
        "outputId": "3036a56e-f8b2-4620-be50-a9dcf5843451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "!mkdir model\n",
        "!python -m spacy train en /model train.json valid.json -n 10 -p ner"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: /model\u001b[0m\n",
            "Training pipeline: ['ner']\n",
            "Starting with blank model 'en'\n",
            "Counting training words (limit=0)\n",
            "\n",
            "Itn  NER Loss   NER P   NER R   NER F   Token %  CPU WPS\n",
            "---  ---------  ------  ------  ------  -------  -------\n",
            "  1  20982.361  80.211  79.401  79.804  100.000    26187\n",
            "  2  10434.342  85.042  84.197  84.617  100.000    28392\n",
            "  3   7378.492  86.688  86.250  86.469  100.000    28138\n",
            "  4   5153.517  87.453  86.924  87.188  100.000    27826\n",
            "  5   4222.710  87.970  87.378  87.673  100.000    28317\n",
            "  6   3736.055  87.955  87.496  87.725  100.000    28175\n",
            "  7   3148.677  88.092  87.647  87.869  100.000    27980\n",
            "  8   2734.978  88.505  87.984  88.244  100.000    28473\n",
            "  9   2685.986  88.346  87.900  88.122  100.000    28150\n",
            " 10   2424.183  88.455  88.068  88.261  100.000    27847\n",
            "\u001b[38;5;2m✔ Saved model to output directory\u001b[0m\n",
            "/model/model-final\n",
            "\u001b[2K\u001b[38;5;2m✔ Created best model\u001b[0m\n",
            "/model/model-best\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F9_zpAar_q_",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OfrUd6CoW4Q",
        "colab_type": "code",
        "outputId": "6d3e6d48-4939-44b0-e647-8697a4348b04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!python -m spacy evaluate /model/model-best test.json -R"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "Time      1.70 s\n",
            "Words     46666 \n",
            "Words/s   27497 \n",
            "TOK       100.00\n",
            "POS       0.00  \n",
            "UAS       0.00  \n",
            "LAS       0.00  \n",
            "NER P     81.40 \n",
            "NER R     81.96 \n",
            "NER F     81.68 \n",
            "Textcat   0.00  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUKePb2Yff7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1wobdm1f1L4",
        "colab_type": "text"
      },
      "source": [
        "# Load CLI trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBHFivfbh8nW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d43d09d-c6f6-4c8d-9e43-2e674ba59525"
      },
      "source": [
        "!pip install mlflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/a7/40679fdb5ac44ad922902b560818682038be169f88c23ad719b9d1f82090/mlflow-1.8.0-py3-none-any.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 4.7MB/s \n",
            "\u001b[?25hCollecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/fa/f54f5662e0eababf0c49e92fd94bf178888562c0e7b677c8941bbbcd1bd6/querystring_parser-1.2.4.tar.gz\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.0.3)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading https://files.pythonhosted.org/packages/74/72/167af24b6df90e1c9db21d4d3a1d67573f35a4ec2376eaebd1ac4e1bbf03/prometheus_flask_exporter-0.13.0.tar.gz\n",
            "Collecting docker>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/74/379a9d30b1620def158c40b88c43e01c1936a287ebb97afab0699c601c57/docker-4.2.0-py2.py3-none-any.whl (143kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 47.1MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 54.1MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.21.0)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.1.2)\n",
            "Collecting sqlalchemy<=1.3.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/47/35edeb0f86c0b44934c05d961c893e223ef27e79e1f53b5e6f14820ff553/SQLAlchemy-1.3.13.tar.gz (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 46.6MB/s \n",
            "\u001b[?25hCollecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/1a/0df85d2bddbca33665d2148173d3281b290ac054b5f50163ea735740ac7b/GitPython-3.1.1-py3-none-any.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3.1)\n",
            "Collecting gunicorn; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (7.1.1)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/d1/fe0ba3d5c2b4b76ec035aa243bbc2fd0d60607a391f192ebe1656e17a4e2/databricks-cli-0.10.0.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hCollecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/a7b98aa9256c8843f92878966dc3d8d914c14aad97e2c5ce4798d5743e07/simplejson-3.17.0.tar.gz (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.13)\n",
            "Collecting gorilla\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/56/5a683944cbfc77e429c6f03c636ca50504a785f60ffae91ddd7f5f7bb520/gorilla-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mlflow) (2018.9)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow) (0.7.1)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 48.1MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/78/f6ade1e18aebda570eed33b7c534378d9659351cadce2fcbc7b31be5f615/Mako-1.1.2-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->mlflow) (46.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2.8)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/52/ca35448b56c53a079d3ffe18b1978c6e424f6d4df02404877094c89f5bfb/gitdb-4.0.4-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.7)\n",
            "Collecting configparser>=0.3.5\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->mlflow) (1.1.1)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/27/b1/e379cfb7c07bbf8faee29c4a1a2469dbea525f047c2b454c4afdefa20a30/smmap-3.0.2-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: alembic\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159543 sha256=059df4186f96ba1d210b9aa25e99410ea711ac63c2f9f66b7c198ebe3818d87c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built alembic\n",
            "Building wheels for collected packages: querystring-parser, prometheus-flask-exporter, sqlalchemy, databricks-cli, simplejson\n",
            "  Building wheel for querystring-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for querystring-parser: filename=querystring_parser-1.2.4-cp36-none-any.whl size=7079 sha256=7a0995dd15f751056d61bc974275ce014fcaad26ed9288676ec816a2671ff019\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/41/34/23ebf5d1089a9aed847951e0ee375426eb4ad0a7079d88d41e\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.13.0-cp36-none-any.whl size=14946 sha256=5b4a0234c8fac649e8b8287aafcef9a949c55d9d6c2fa874434440ba15b30367\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/2f/a3/c81e6aa99897467c82d523858738fb8c94d1d43e500da45dc2\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.13-cp36-cp36m-linux_x86_64.whl size=1217128 sha256=b15050b8954856c48cb4e4dc32731ea72d690e84c27c52d5cdc369e9eb77644b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/35/98/4c9cb3fd63d21d5606b972dd70643769745adf60e622467b71\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.10.0-cp36-none-any.whl size=84285 sha256=b8291ed8b0b2f0ad276365b9b70521ba96fca4165dcc63522142df9eb716e812\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/e5/2d/a19c0bfd38005176063f130d72de17cb3d2d32c0ee384e7493\n",
            "  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simplejson: filename=simplejson-3.17.0-cp36-cp36m-linux_x86_64.whl size=114209 sha256=f8c6b0cdd940455224bccc45625ea02d1e2d23bca7baae518248d4f1e1299e51\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/c0/83/dcd0339abb2640544bb8e0938aab2d069cef55e5647ce6e097\n",
            "Successfully built querystring-parser prometheus-flask-exporter sqlalchemy databricks-cli simplejson\n",
            "Installing collected packages: querystring-parser, prometheus-flask-exporter, websocket-client, docker, python-editor, sqlalchemy, Mako, alembic, smmap, gitdb, gitpython, gunicorn, configparser, databricks-cli, simplejson, gorilla, mlflow\n",
            "  Found existing installation: SQLAlchemy 1.3.16\n",
            "    Uninstalling SQLAlchemy-1.3.16:\n",
            "      Successfully uninstalled SQLAlchemy-1.3.16\n",
            "Successfully installed Mako-1.1.2 alembic-1.4.2 configparser-5.0.0 databricks-cli-0.10.0 docker-4.2.0 gitdb-4.0.4 gitpython-3.1.1 gorilla-0.3.0 gunicorn-20.0.4 mlflow-1.8.0 prometheus-flask-exporter-0.13.0 python-editor-1.0.4 querystring-parser-1.2.4 simplejson-3.17.0 smmap-3.0.2 sqlalchemy-1.3.13 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "configparser"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-wVifxRhS0z",
        "colab_type": "code",
        "outputId": "b168e3fb-7a3e-4a81-b4bc-747b066e89c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import spacy\n",
        "import mlflow.spacy\n",
        "\n",
        "# training data\n",
        "PREDICT_DATA = [\n",
        "    (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
        "    (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOC\"), (18, 24, \"LOC\")]}),\n",
        "]\n",
        "\n",
        "# load the cli trianed model into memory\n",
        "nlp = spacy.load(\"/model/model-best\")\n",
        "\n",
        "# Log the spaCy model using mlflow\n",
        "mlflow.spacy.save_model(spacy_model=nlp, path=\"/content/saved-model\")\n",
        "mlflow.spacy.log_model(spacy_model=nlp, artifact_path='mlflow-model')\n",
        "model_uri = \"runs:/{run_id}/{artifact_path}\".format(\n",
        "    run_id=mlflow.active_run().info.run_id,\n",
        "    artifact_path='mlflow-model')\n",
        "\n",
        "print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)\n",
        "\n",
        "# Load the model using mlflow and use it to predict data\n",
        "nlp2 = mlflow.spacy.load_model(model_uri=model_uri)\n",
        "for text, _ in PREDICT_DATA:\n",
        "    doc = nlp2(text)\n",
        "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "    print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020/04/30 18:47:32 WARNING mlflow.spacy: Generating only the spacy flavor for the provided spacy model. This means the model can be loaded back via `mlflow.spacy.load_model`, but cannot be loaded back using pyfunc APIs like `mlflow.pyfunc.load_model` or via the `mlflow models` CLI commands. MLflow will only generate the pyfunc flavor for spacy models containing a pipeline component that is an instance of spacy.pipeline.TextCategorizer.\n",
            "2020/04/30 18:47:32 WARNING mlflow.spacy: Generating only the spacy flavor for the provided spacy model. This means the model can be loaded back via `mlflow.spacy.load_model`, but cannot be loaded back using pyfunc APIs like `mlflow.pyfunc.load_model` or via the `mlflow models` CLI commands. MLflow will only generate the pyfunc flavor for spacy models containing a pipeline component that is an instance of spacy.pipeline.TextCategorizer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved in run c79f3a50087443a899b18d148c234879\n",
            "Entities [('Shaka Khan', 'PER')]\n",
            "Tokens [('Who', '', 2), ('is', '', 2), ('Shaka', 'PER', 3), ('Khan', 'PER', 1), ('?', '', 2)]\n",
            "Entities [('London', 'LOC'), ('Berlin', 'LOC')]\n",
            "Tokens [('I', '', 2), ('like', '', 2), ('London', 'LOC', 3), ('and', '', 2), ('Berlin', 'LOC', 3), ('.', '', 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jnFSHOJ4YMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkAERqsJhWtq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "afc0cb1b-dcc4-4e80-ec14-f3ecc4f72efb"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "!cd /content/saved-model && zip -r /content/model.zip .\n",
        "files.download('/content/model.zip') "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: MLmodel (deflated 22%)\n",
            "  adding: conda.yaml (deflated 19%)\n",
            "  adding: model.spacy/ (stored 0%)\n",
            "  adding: model.spacy/ner/ (stored 0%)\n",
            "  adding: model.spacy/ner/model (deflated 7%)\n",
            "  adding: model.spacy/ner/moves (deflated 63%)\n",
            "  adding: model.spacy/ner/cfg (deflated 48%)\n",
            "  adding: model.spacy/vocab/ (stored 0%)\n",
            "  adding: model.spacy/vocab/lexemes.bin (deflated 72%)\n",
            "  adding: model.spacy/vocab/vectors (deflated 45%)\n",
            "  adding: model.spacy/vocab/strings.json (deflated 67%)\n",
            "  adding: model.spacy/vocab/key2row (stored 0%)\n",
            "  adding: model.spacy/meta.json (deflated 41%)\n",
            "  adding: model.spacy/tokenizer (deflated 79%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56aT8uJha5O8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ee504bff-76ff-4cd9-9812-3e01c862ed72"
      },
      "source": [
        "# reproduce MLflow bug\n",
        "!mlflow models serve -m /content/saved-model"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pygments/util.py:27: DeprecationWarning: Flags not at the start of the expression '<(.+?)(\\\\s.*?)?>.*?</' (truncated)\n",
            "  tag_re = re.compile(r'<(.+?)(\\s.*?)?>.*?</.+?>(?uism)')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/mlflow\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 1259, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 1259, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/models/cli.py\", line 56, in serve\n",
            "    install_mlflow=install_mlflow).serve(model_uri=model_uri, port=port,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/models/cli.py\", line 167, in _get_flavor_backend\n",
            "    raise Exception(\"No suitable flavor backend was found for the model.\")\n",
            "Exception: No suitable flavor backend was found for the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peHerh1Ka7AQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}